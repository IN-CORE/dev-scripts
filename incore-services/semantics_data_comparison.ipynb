{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore import IncoreClient, DataService\n",
    "from pyincore.dataset import Dataset\n",
    "import requests as rs\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import csv\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Clients and estabilish connections to dataservice and mongodb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_client = IncoreClient()\n",
    "dev_client = IncoreClient(\"https://incore-dev.ncsa.illinois.edu\")\n",
    "\n",
    "prod_dataservice = DataService(client=prod_client)\n",
    "dev_dataservice = DataService(client=dev_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_username = \"root\"\n",
    "mongo_password_dev = os.getenv(\"PWDEV\")\n",
    "host = \"localhost\"\n",
    "port_dev = \"27019\"  # dev\n",
    "\n",
    "mongoclient_dev = MongoClient(\n",
    "    \"mongodb://%s:%s@%s:%s\"\n",
    "    % (mongo_username, mongo_password_dev, host, port_dev)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_username = \"root\"\n",
    "mongo_password_prod = os.getenv(\"PWPROD\")\n",
    "host = \"localhost\"\n",
    "port_prod = \"27020\"  # prod\n",
    "\n",
    "mongoclient_prod: MongoClient = MongoClient(\n",
    "    \"mongodb://%s:%s@%s:%s\"\n",
    "    % (mongo_username, mongo_password_prod, host, port_prod)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load unique datatypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the unique list of datatypes\n",
    "with open(\"pyincore_unique_data_types.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    unique_data_types = [datatype[0] for datatype in list(reader)[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load dataset ids from mongodb without space consideration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids_from_mongodb(\n",
    "    mongoclient: MongoClient, datatypes: List[str]\n",
    ") -> Dict[str, List[Dict[str, str]]]:\n",
    "    unique_datatype_dataset_ids = defaultdict(list)\n",
    "    for datatype in datatypes:\n",
    "        for document in mongoclient[\"datadb\"][\"Dataset\"].find(\n",
    "            {\"dataType\": datatype, \"deleted\": False}\n",
    "        ):\n",
    "            unique_datatype_dataset_ids[datatype].append(\n",
    "                {\n",
    "                    \"id\": str(document[\"_id\"]),\n",
    "                    \"creator\": str(document[\"creator\"]),\n",
    "                    \"format\": str(document[\"format\"]),\n",
    "                }\n",
    "            )\n",
    "    return unique_datatype_dataset_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_unique_datatype_dataset_ids = load_ids_from_mongodb(\n",
    "    mongoclient_prod, unique_data_types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load dataset ids from API endpoint with ability to filter out via Space\n",
    "\n",
    "The spaces considered are:\n",
    "\n",
    "- ergo\n",
    "- incore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_url = \"https://incore.ncsa.illinois.edu/data/api/datasets?space={}&type={}&limit=100000&skip=0\"\n",
    "dev_url = \"https://incore-dev.ncsa.illinois.edu/data/api/datasets?space={}&type={}&limit=100000&skip=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids_from_api(\n",
    "    url: str, spaces: List[str], datatypes: List[str]\n",
    ") -> Dict[str, List[Dict[str, str]]]:\n",
    "    unique_datatype_dataset_ids = defaultdict(list)\n",
    "    header = {\n",
    "        \"Authorization\": f\"bearer {os.getenv('TOKEN')}\",\n",
    "    }\n",
    "    for datatype in datatypes:\n",
    "        for space in spaces:\n",
    "            response = rs.get(url.format(space, datatype), headers=header)\n",
    "            if response.status_code != 200:\n",
    "                print(\n",
    "                    f\"Error: {response.status_code} for {datatype} in {space}\"\n",
    "                )\n",
    "                continue\n",
    "            for dataset in response.json():\n",
    "                if dataset[\"deleted\"]:\n",
    "                    continue\n",
    "                unique_datatype_dataset_ids[datatype].append(\n",
    "                    {\n",
    "                        \"id\": dataset[\"id\"],\n",
    "                        \"creator\": dataset[\"creator\"],\n",
    "                        \"format\": dataset[\"format\"],\n",
    "                        \"space\": space,\n",
    "                    }\n",
    "                )\n",
    "    return unique_datatype_dataset_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip below cell and load the extracted ids directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_filtered_dataset_ids_prod = load_ids_from_api(\n",
    "    prod_url, [\"ergo\", \"incore\"], unique_data_types\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_filtered_dataset_ids_dev = load_ids_from_api(\n",
    "    dev_url, [\"ergo\", \"incore\"], unique_data_types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip to here for loading extracted ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file for faster access next time\n",
    "with open(\"pyincore_prod_unique_datatypes_dataset_ids.json\", \"w\") as f:\n",
    "    json.dump(space_filtered_dataset_ids_prod, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file for faster access next time\n",
    "with open(\"pyincore_dev_unique_datatypes_dataset_ids.json\", \"w\") as f:\n",
    "    json.dump(space_filtered_dataset_ids_dev, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pyincore_prod_unique_datatypes_dataset_ids.json\", \"r\") as f:\n",
    "    space_filtered_dataset_ids_prod = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pyincore_dev_unique_datatypes_dataset_ids.json\", \"r\") as f:\n",
    "    space_filtered_dataset_ids_dev = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unique_data_types))\n",
    "print(len(space_filtered_dataset_ids_prod.keys()))\n",
    "datasets_of_datatype_not_in_incore_ergo_space = list(\n",
    "    set(unique_data_types) - set(space_filtered_dataset_ids_prod.keys())\n",
    ")\n",
    "print(datasets_of_datatype_not_in_incore_ergo_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(unique_data_types))\n",
    "print(len(space_filtered_dataset_ids_dev.keys()))\n",
    "datasets_of_datatype_not_in_incore_ergo_space = list(\n",
    "    set(unique_data_types) - set(space_filtered_dataset_ids_dev.keys())\n",
    ")\n",
    "print(datasets_of_datatype_not_in_incore_ergo_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset Objects from the dataset IDs collected\n",
    "\n",
    "After loading the dataset, we will need to load it based on the format the dataset is in.\n",
    "\n",
    "Ex:\n",
    "| _Format_ | _Dataset Function to use_ |\n",
    "| ---------- | --------------------------- |\n",
    "| shapefile | `get_dataframe_from_shapefile` |\n",
    "| shp-network | not sure |\n",
    "| json | `get_json_reader` |\n",
    "| table | `get_csv_reader` or `get_dataframe_from_csv` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(\n",
    "    datasets: List[dict], dataservice: DataService\n",
    ") -> List[Dataset]:\n",
    "    # download and get a list of all the datasets in the database for a datatype\n",
    "    dataset_objects: List[Dataset] = []\n",
    "    for ds in datasets:\n",
    "        dataset_objects.append(\n",
    "            Dataset.from_data_service(ds[\"id\"], dataservice)\n",
    "        )\n",
    "    return dataset_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df = Dataset.from_data_service(\n",
    "    \"5d25118eb9219c0692cd7527\", prod_dataservice\n",
    ").get_dataframe_from_shapefile()\n",
    "# ds_df = Dataset.from_data_service(\"5d25118eb9219c0692cd7527\", dev_dataservice).get_dataframe_from_csv()\n",
    "ds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"incore:tornadoWindfield\" in space_filtered_dataset_ids_prod.keys())\n",
    "print(\"incore:tornadoWindfield\" in space_filtered_dataset_ids_dev.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_objs = get_datasets(\n",
    "    space_filtered_dataset_ids_prod[\"incore:epfDamageRatios\"],\n",
    "    prod_dataservice,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_objs = get_datasets(\n",
    "    space_filtered_dataset_ids_dev[\"ergo:bridges\"],\n",
    "    dev_dataservice,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset_objs))\n",
    "print(dataset_objs[0].format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_obj_dfs = []\n",
    "\n",
    "for ds_ob in dataset_objs:\n",
    "    if ds_ob.format == \"shapefile\":\n",
    "        dataset_obj_dfs.append(ds_ob.get_dataframe_from_shapefile())\n",
    "    elif ds_ob.format == \"table\":\n",
    "        dataset_obj_dfs.append(ds_ob.get_dataframe_from_csv())\n",
    "    else:\n",
    "        msg = \"Dataset format not in consideration for id {} in {} format\".format(\n",
    "            ds_ob.id, ds_ob.format\n",
    "        )\n",
    "        dataset_obj_dfs.append(msg)\n",
    "        print(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ds_ob in dataset_objs:\n",
    "    print(ds_ob.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(dataset_obj_dfs):\n",
    "    if isinstance(df, str):\n",
    "        print(df)\n",
    "        continue\n",
    "    print(\"Dataset {}\".format(dataset_objs[i].id))\n",
    "    print(df.dtypes)\n",
    "    print(\"=\" * 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_obj_dfs[0].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_obj_dfs[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear prod cache files\n",
    "prod_client.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear dev cache files\n",
    "dev_client.clear_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
