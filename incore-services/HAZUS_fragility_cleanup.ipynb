{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87aff927-8fc1-44a6-a886-7e4445a7fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f425c02f-8a8d-4afa-8e93-152c7abb997f",
   "metadata": {},
   "source": [
    "### Compare struct_typ with exisiing HAZUS mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034722b8-56e0-4be9-99c2-26cfe0e815ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory containing the JSON files\n",
    "fragility_folder = \"./Dylan_fragilities/FragilityJsons\"\n",
    "hazard_type = \"TS\" # or \"EQ\"\n",
    "\n",
    "# Define a regex pattern to extract structural types\n",
    "filename_pattern = re.compile(f\"LocalCurveSet-{hazard_type}-(.*?)-(High|Mod|Low)Code\\.json\")\n",
    "\n",
    "# Set to store unique structural types\n",
    "structural_types = set()\n",
    "\n",
    "# Loop through all files in the directory\n",
    "for filename in os.listdir(fragility_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        structural_type = match.group(1)\n",
    "        structural_types.add(structural_type)\n",
    "\n",
    "# Print all unique structural types\n",
    "print(\"Unique Structural Types:\")\n",
    "for st in sorted(structural_types):\n",
    "    print(st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54eea7e0-d41d-49f3-8e4c-36e1a7c1e75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyincore import FragilityService, IncoreClient\n",
    "\n",
    "hazus_mapping_id_1 = \"5b47b2d9337d4a36187c7563\" # Hazus Building Fragility Mapping\n",
    "hazus_mapping_id_2 = \"5b47b350337d4a3629076f2c\" # Default Building Fragility Mapping 1.0\n",
    "\n",
    "client = IncoreClient()\n",
    "\n",
    "# Initialize FragilityService\n",
    "fragility_service = FragilityService(client)\n",
    "\n",
    "# Fetch fragility mappings\n",
    "hazus_mapping_1 = fragility_service.get_mapping(hazus_mapping_id_1)\n",
    "hazus_mapping_2 = fragility_service.get_mapping(hazus_mapping_id_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d19e49-c07a-4051-adc5-50b219139b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract struct_typ values from mapping rules\n",
    "def extract_structural_types_from_mapping(mapping):\n",
    "    mapping_types = set()\n",
    "    \n",
    "    for mapping_entry in mapping.get(\"mappings\", []):  # Iterate through mapping list\n",
    "        for rule_group in mapping_entry.get(\"rules\", []):  # \"rules\" is a list of lists\n",
    "            for rule in rule_group:\n",
    "                if \"struct_typ EQUALS\" in rule:\n",
    "                    struct_type = rule.split(\"EQUALS\")[1].strip()\n",
    "                    mapping_types.add(struct_type)\n",
    "    \n",
    "    return mapping_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225dce9-b316-45b6-8a39-1578cc025469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structural types from the mapping rules\n",
    "mapping_1_types = extract_structural_types_from_mapping(hazus_mapping_1)\n",
    "mapping_2_types = extract_structural_types_from_mapping(hazus_mapping_2)\n",
    "\n",
    "# Compare structural types\n",
    "missing_from_mapping_1 = structural_types - mapping_1_types\n",
    "missing_from_mapping_2 = structural_types - mapping_2_types\n",
    "\n",
    "print(\"\\nResults:\")\n",
    "print(\"Hazus Mapping 1:\")\n",
    "if missing_from_mapping_1:\n",
    "    print(\" - Missing structural types:\", missing_from_mapping_1)\n",
    "else:\n",
    "    print(\" - Contains all structural types.\")\n",
    "\n",
    "print(\"\\nHazus Mapping 2:\")\n",
    "if missing_from_mapping_2:\n",
    "    print(\" - Missing structural types:\", missing_from_mapping_2)\n",
    "else:\n",
    "    print(\" - Contains all structural types.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c15544f-4be2-4409-af25-5ce7c4873f62",
   "metadata": {},
   "source": [
    "### Find overlapping existing fragilities next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f2d23-438b-43aa-944e-17ea28daea68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store local fragility curve expressions\n",
    "local_fragility_curves = {}\n",
    "\n",
    "# Iterate over JSON files in the directory\n",
    "for filename in os.listdir(fragility_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        structural_type = match.group(1)\n",
    "        code_level = match.group(2)\n",
    "        file_path = os.path.join(fragility_folder, filename)\n",
    "        \n",
    "        with open(file_path, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "            # Extract all fragility curve expressions\n",
    "            expressions = []\n",
    "            for fragility_curve in data.get('fragilityCurves', []):\n",
    "                for rule in fragility_curve.get('rules', []):\n",
    "                    if 'expression' in rule and rule['expression']:\n",
    "                        expressions.append(rule['expression'])\n",
    "            \n",
    "            # Store extracted expressions with the structural type and code level as key\n",
    "            local_fragility_curves[f\"{structural_type}-{code_level}\"] = expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743441bf-313b-4726-aac9-ec45328cecb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for fragilities related to \"HAZUS MH 2.1\"\n",
    "hazus_fragilities = fragility_service.search_dfr3_sets(\"HAZUS MH 2.1\")\n",
    "# Filter results to only include those belonging to the 'incore' space\n",
    "hazus_fragilities = [\n",
    "    fragility for fragility in hazus_fragilities if \"incore\" in fragility.get(\"spaces\", [])\n",
    "]\n",
    "\n",
    "# Extract relevant information from HAZUS fragilities\n",
    "hazus_fragility_curves = {}\n",
    "for hazus_fragility in hazus_fragilities:\n",
    "    description = hazus_fragility.get(\"description\", \"\")\n",
    "    if description:\n",
    "        # Normalize HAZUS descriptions (e.g., \"W1 – high code\" → \"W1-High\")\n",
    "        match = re.search(r\"([A-Za-z0-9]+)\\s*–\\s*(high|mod|low) code\", description, re.IGNORECASE)\n",
    "        if match:\n",
    "            structural_type = match.group(1).strip().upper()\n",
    "            code_level = match.group(2).capitalize()\n",
    "            key = f\"{structural_type}-{code_level}\"\n",
    "           \n",
    "            # Extract all fragility curve expressions\n",
    "            expressions = []\n",
    "            for fragility_curve in hazus_fragility.get('fragilityCurves', []):\n",
    "                for rule in fragility_curve.get('rules', []):\n",
    "                    if 'expression' in rule and rule['expression']:\n",
    "                        expressions.append(rule['expression'])\n",
    "        \n",
    "            # Store extracted expressions with the structural type and code level as key\n",
    "            hazus_fragility_curves[f\"{structural_type}-{code_level}\"] = expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4160fdb0-122d-4bbb-b159-9e560a62b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazus_fragility_ids = [fragility.get(\"id\") for fragility in hazus_fragilities]\n",
    "hazus_fragility_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a9379c-004b-4376-b644-e495a0259847",
   "metadata": {},
   "outputs": [],
   "source": [
    "hazus_fragility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b653c0b-bb53-4f16-ac8d-e5f39fe11d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare local and HAZUS fragility curves\n",
    "print(\"\\nComparison of Local vs. HAZUS Fragility Curves:\")\n",
    "for key, local_expressions in local_fragility_curves.items():\n",
    "    hazus_expressions = hazus_fragility_curves.get(key, [])\n",
    "    \n",
    "    if hazus_expressions:\n",
    "        print(f\"Match found for {key}\")\n",
    "        \n",
    "        # Check if expressions match\n",
    "        if set(local_expressions) == set(hazus_expressions):\n",
    "            print(\"  ✅ Expressions Match!\")\n",
    "        else:\n",
    "            print(\"  ❌ Expressions Differ!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f17dfa-6aec-43fe-8aed-d1f9b5fb91d3",
   "metadata": {},
   "source": [
    "### Posting fragilites to INCORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5772de7-883e-4354-86b3-7d8f4006123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a pattern to extract structural type and design level from filenames\n",
    "filename_pattern = re.compile(f\"LocalCurveSet-{hazard_type}-(.*?)-(High|Mod|Low)Code\\.json\")\n",
    "\n",
    "# Dictionary to store posted fragility IDs\n",
    "fragility_id_mapping = {}\n",
    "\n",
    "# Iterate over JSON files and post them to IN-CORE\n",
    "for filename in os.listdir(fragility_folder):\n",
    "    match = filename_pattern.match(filename)\n",
    "    if match:\n",
    "        structural_type = match.group(1).strip().upper()\n",
    "        design_level = match.group(2).capitalize()\n",
    "        description = f\"{structural_type} - {design_level} Code\"\n",
    "\n",
    "        file_path = os.path.join(fragility_folder, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            fragility_data = json.load(file)\n",
    "\n",
    "            # Remove ID if exists\n",
    "            fragility_data.pop(\"id\", None)\n",
    "\n",
    "            # Recursively replace \"momentumflux\" with \"Mmax\" in the entire JSON structure\n",
    "            def replace_momentumflux(data):\n",
    "                if isinstance(data, dict):\n",
    "                    return {key: replace_momentumflux(value) for key, value in data.items()}\n",
    "                elif isinstance(data, list):\n",
    "                    return [replace_momentumflux(item) for item in data]\n",
    "                elif isinstance(data, str) and \"momentumflux\" in data.lower():\n",
    "                    return data.lower().replace(\"momentumflux\", \"Mmax\")\n",
    "                return data\n",
    "\n",
    "            fragility_data = replace_momentumflux(fragility_data)\n",
    "\n",
    "            # Update description and metadata\n",
    "            fragility_data[\"description\"] = description\n",
    "            fragility_data[\"authors\"] = [\"HAZUS MH 2.1\"]\n",
    "\n",
    "            # Post to IN-CORE\n",
    "            posted_fragility = fragility_service.create_dfr3_set(fragility_data)\n",
    "\n",
    "            # Store the newly created fragility ID\n",
    "            fragility_id_mapping[f\"{structural_type}-{design_level}\"] = posted_fragility[\"id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d33aa83-88ec-46e9-9973-13c9c0378806",
   "metadata": {},
   "outputs": [],
   "source": [
    "fragility_id_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17493b22-9391-4ebf-b6bf-a380cd29ad1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and modify fragility mapping\n",
    "mapping_path = f\"./Dylan_fragilities/{hazard_type}MappingSet.json\"\n",
    "with open(mapping_path, 'r') as file:\n",
    "    mapping_data = json.load(file)\n",
    "\n",
    "# Update mapping name\n",
    "if hazard_type == \"EQ\":\n",
    "    mapping_data[\"name\"] = \"HAZUS 2.1 Earthquake Building Fragility Mapping (NSI Data)\"\n",
    "elif hazard_type == \"TS\":\n",
    "    mapping_data[\"name\"] = \"HAZUS 2.1 Tsunami Building Fragility Mapping (NSI Data)\"\n",
    "\n",
    "# Remove ID if exists\n",
    "mapping_data.pop(\"id\", None)\n",
    "\n",
    "# Replace fragility IDs in mapping\n",
    "for entry in mapping_data.get(\"mappings\", []):\n",
    "    if hazard_type == \"EQ\":\n",
    "        entry_key = \"Non-Retrofit Fragility ID Code\"\n",
    "    elif hazard_type == \"TS\":\n",
    "        entry_key = \"Non-Retrofit MomentumFlux Fragility ID Code\"\n",
    "    fragility_filename = entry[\"entry\"].get(entry_key)\n",
    "    \n",
    "    # Extract structural type and design level from filename\n",
    "    match = filename_pattern.match(fragility_filename)\n",
    "    if match:\n",
    "        structural_type = match.group(1).strip().upper()\n",
    "        design_level = match.group(2).capitalize()\n",
    "        key = f\"{structural_type}-{design_level}\"\n",
    "\n",
    "        # Replace with posted fragility ID\n",
    "        if key in fragility_id_mapping:\n",
    "            entry[\"entry\"][entry_key] = fragility_id_mapping[key]\n",
    "\n",
    "# Post updated mapping to IN-CORE\n",
    "posted_mapping = fragility_service.create_mapping(mapping_data)\n",
    "\n",
    "# Display posted mapping ID\n",
    "print(f\"Posted Mapping ID: {posted_mapping['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fb03ee-27b0-4ccb-b6c0-303e2a222758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to space\n",
    "from pyincore import SpaceService\n",
    "\n",
    "spacesvc = SpaceService(client)\n",
    "\n",
    "space_name = \"incore\"\n",
    "\n",
    "# Add the posted fragility to the IN-CORE space\n",
    "for key, fragility_id in fragility_id_mapping.items():\n",
    "    space = spacesvc.add_to_space_by_name(space_name, fragility_id)\n",
    "    assert fragility_id in space[\"members\"]  # Ensure it was successfully added\n",
    "\n",
    "# add mapping id\n",
    "space = spacesvc.add_to_space_by_name(space_name, posted_mapping[\"id\"])\n",
    "assert fragility_id in space[\"members\"]  # Ensure it was successfully added"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5a15a6d1-d7bf-4997-95c6-53ff02533e72",
   "metadata": {},
   "source": [
    "# Iterate over the fragility IDs and delete them\n",
    "for key, fragility_id in fragility_id_mapping.items():\n",
    "    try:\n",
    "        response = fragility_service.delete_dfr3_set(fragility_id)\n",
    "        print(f\"✅ Deleted {key} (ID: {fragility_id})\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to delete {key} (ID: {fragility_id}) - Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ebac4-aede-4b71-8e19-49fad1cfa7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
