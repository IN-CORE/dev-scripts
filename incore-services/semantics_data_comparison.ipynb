{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyincore import IncoreClient, DataService\n",
    "from pyincore.dataset import Dataset\n",
    "import requests as rs\n",
    "import os\n",
    "from pymongo import MongoClient\n",
    "import csv\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Clients and estabilish connections to dataservice and mongodb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection successful to IN-CORE services. pyIncore version detected: 1.12.0\n",
      "Connection successful to IN-CORE services. pyIncore version detected: 1.12.0\n"
     ]
    }
   ],
   "source": [
    "prod_client = IncoreClient()\n",
    "dev_client = IncoreClient(\"https://incore-dev.ncsa.illinois.edu\")\n",
    "\n",
    "prod_dataservice = DataService(client=prod_client)\n",
    "dev_dataservice = DataService(client=dev_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_username = \"root\"\n",
    "mongo_password_dev = os.getenv(\"PWDEV\")\n",
    "host = \"localhost\"\n",
    "port_dev = \"27019\"  # dev\n",
    "\n",
    "mongoclient_dev = MongoClient(\n",
    "    \"mongodb://%s:%s@%s:%s\"\n",
    "    % (mongo_username, mongo_password_dev, host, port_dev)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_username = \"root\"\n",
    "mongo_password_prod = os.getenv(\"PWPROD\")\n",
    "host = \"localhost\"\n",
    "port_prod = \"27020\"  # prod\n",
    "\n",
    "mongoclient_prod: MongoClient = MongoClient(\n",
    "    \"mongodb://%s:%s@%s:%s\"\n",
    "    % (mongo_username, mongo_password_prod, host, port_prod)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load unique datatypes found out by Chen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the unique list of datatypes\n",
    "with open(\"pyincore_unique_data_types.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    unique_data_types = [datatype[0] for datatype in list(reader)[1:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load dataset ids from mongodb without space consideration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids_from_mongodb(\n",
    "    mongoclient: MongoClient, datatypes: List[str]\n",
    ") -> Dict[str, List[Dict[str, str]]]:\n",
    "    unique_datatype_dataset_ids = defaultdict(list)\n",
    "    for datatype in datatypes:\n",
    "        for document in mongoclient[\"datadb\"][\"Dataset\"].find(\n",
    "            {\"dataType\": datatype, \"deleted\": False}\n",
    "        ):\n",
    "            unique_datatype_dataset_ids[datatype].append(\n",
    "                {\n",
    "                    \"id\": str(document[\"_id\"]),\n",
    "                    \"creator\": str(document[\"creator\"]),\n",
    "                    \"format\": str(document[\"format\"]),\n",
    "                }\n",
    "            )\n",
    "    return unique_datatype_dataset_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_unique_datatype_dataset_ids = load_ids_from_mongodb(\n",
    "    mongoclient_prod, unique_data_types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to load dataset ids from API endpoint with ability to filter out via Space\n",
    "\n",
    "The spaces considered are:\n",
    "\n",
    "- ergo\n",
    "- incore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_url = \"https://incore.ncsa.illinois.edu/data/api/datasets?space={}&type={}&limit=100000&skip=0\"\n",
    "dev_url = \"https://incore-dev.ncsa.illinois.edu/data/api/datasets?space={}&type={}&limit=100000&skip=0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ids_from_api(\n",
    "    url: str, spaces: List[str], datatypes: List[str]\n",
    ") -> Dict[str, List[Dict[str, str]]]:\n",
    "    unique_datatype_dataset_ids = defaultdict(list)\n",
    "    header = {\n",
    "        \"Authorization\": f\"bearer {os.getenv('TOKEN')}\",\n",
    "    }\n",
    "    for datatype in datatypes:\n",
    "        for space in spaces:\n",
    "            response = rs.get(url.format(space, datatype), headers=header)\n",
    "            if response.status_code != 200:\n",
    "                print(\n",
    "                    f\"Error: {response.status_code} for {datatype} in {space}\"\n",
    "                )\n",
    "                continue\n",
    "            for dataset in response.json():\n",
    "                if dataset[\"deleted\"]:\n",
    "                    continue\n",
    "                unique_datatype_dataset_ids[datatype].append(\n",
    "                    {\n",
    "                        \"id\": dataset[\"id\"],\n",
    "                        \"creator\": dataset[\"creator\"],\n",
    "                        \"format\": dataset[\"format\"],\n",
    "                        \"space\": space,\n",
    "                    }\n",
    "                )\n",
    "    return unique_datatype_dataset_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip below cell and load the extracted ids directly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "space_filtered_dataset_ids_prod = load_ids_from_api(\n",
    "    prod_url, [\"ergo\", \"incore\"], unique_data_types\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip to here for loading extracted ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to file for faster access next time\n",
    "with open(\"pyincore_prod_unique_datatypes_dataset_ids.json\", \"w\") as f:\n",
    "    json.dump(space_filtered_dataset_ids_prod, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pyincore_prod_unique_datatypes_dataset_ids.json\", \"r\") as f:\n",
    "    space_filtered_dataset_ids_prod = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_data_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Dataset Objects from the dataset IDs collected\n",
    "\n",
    "After loading the dataset, we will need to load it based on the format the dataset is in.\n",
    "\n",
    "Ex:\n",
    "| _Format_ | _Dataset Function to use_ |\n",
    "| ---------- | --------------------------- |\n",
    "| shapefile | `get_dataframe_from_shapefile` |\n",
    "| shp-network | not sure |\n",
    "| json | `get_json_reader` |\n",
    "| table | `get_csv_reader` or `get_dataframe_from_csv` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(\n",
    "    datasets: List[dict], dataservice: DataService\n",
    ") -> List[Dataset]:\n",
    "    # download and get a list of all the datasets in the database for a datatype\n",
    "    dataset_objects: List[Dataset] = []\n",
    "    for ds in datasets:\n",
    "        dataset_objects.append(\n",
    "            Dataset.from_data_service(ds[\"id\"], dataservice)\n",
    "        )\n",
    "    return dataset_objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n",
      "Dataset already exists locally. Reading from local cached zip.\n",
      "Unzipped folder found in the local cache. Reading from it...\n"
     ]
    }
   ],
   "source": [
    "ergo_bldg_inventory_ver6_datasets = get_datasets(\n",
    "    space_filtered_dataset_ids_prod[\"ergo:buildingInventoryVer6\"],\n",
    "    prod_dataservice,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapefile\n"
     ]
    }
   ],
   "source": [
    "print(ergo_bldg_inventory_ver6_datasets[0].format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf1 = ergo_bldg_inventory_ver6_datasets[0].get_dataframe_from_shapefile()\n",
    "gdf2 = ergo_bldg_inventory_ver6_datasets[1].get_dataframe_from_shapefile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['parid', 'parid_card', 'bldg_id', 'struct_typ', 'str_prob',\n",
       "       'year_built', 'no_stories', 'a_stories', 'b_stories', 'bsmt_type',\n",
       "       'sq_foot', 'gsq_foot', 'occ_type', 'occ_detail', 'major_occ',\n",
       "       'broad_occ', 'appr_bldg', 'repl_cst', 'str_cst', 'nstra_cst',\n",
       "       'nstrd_cst', 'dgn_lvl', 'cont_val', 'efacility', 'dwell_unit',\n",
       "       'str_typ2', 'occ_typ2', 'tract_id', 'guid', 'FID_NEW', 'origin',\n",
       "       'stat_class', 'rmv_improv', 'rmv_land', 'elev', 'period', 'strctid',\n",
       "       'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['strctid', 'Lon', 'Lat', 'archtype', 'parid', 'struct_typ',\n",
       "       'year_built', 'no_stories', 'a_stories', 'b_stories', 'bsmt_type',\n",
       "       'sq_foot', 'gsq_foot', 'occ_type', 'occ_detail', 'major_occ',\n",
       "       'broad_occ', 'appr_bldg', 'repl_cst', 'str_cst', 'nstra_cst',\n",
       "       'nstrd_cst', 'dgn_lvl', 'cont_val', 'efacility', 'dwell_unit',\n",
       "       'str_typ2', 'occ_typ2', 'appr_land', 'appr_tot', 'types', 'failure',\n",
       "       'fun', 'guid', 'geometry'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear prod cache files\n",
    "prod_client.clear_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear dev cache files\n",
    "dev_client.clear_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "incore",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
